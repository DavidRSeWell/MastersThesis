
In this paper we have looked at the AlphaGo family of algorithms in the hopes of shedding some light on how the internals work. We went through the hierarchy of concepts presented in the introduction.  We have taken the perspective of looking at 2 player zero sum games and how they have historically been solved. We then showed how AlphaGo fits into this history. We started with basic RL concepts,MDP, Dynammic Programming, Monte Carlo Methods, Monte Carlo Tree search, Deep RL, and finally AlphaZero. We discussed a bit about what goes into actually building out your own version of the program. Using our own version we looked at a number of experiments that helped us understand how the different parameters of the algorithm affect overall performance. The AlphaZero algorithm is quite elegant but it requires a tremendous amount of tuning. This tuning cost is prohibitively costly in larger domains if you are on a limited budget. That being said the algorithm has proven to be very successful in the game of Go and in other domains. I hope that this paper has helped you to understand AlphaZero more thoroughly and allow you to explore this interesting work by Deepmind. 
